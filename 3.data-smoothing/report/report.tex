\documentclass[11pt, a4paper, titlepage, openright]{article}

\usepackage{amsmath}
\usepackage[font=small,labelfont=bf]{caption}
\usepackage{float}
\restylefloat{figure}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage[titletoc, title]{appendix}
\usepackage{listings}
\usepackage{color}
\usepackage{fixltx2e}
\usepackage[bottom]{footmisc}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=C++,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\footnotesize\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3,
  showstringspaces=false,
  keepspaces=true, 
  columns=flexible
}

\begin{document}
\input{title_page.tex}
\tableofcontents
\newpage

\section{Problem}
    We are given the following set of data points:
    \[
    \begin{tabular}{l | *{7}{c}}
        x & 0.635 & 1.435 & 2.235 & 3.035 & 3.835 & 4.635 & 5.435 \\
        y & 7.50  & 4.35  & 2.97  & 2.20  & 1.70  & 1.28  & 1.00 \\
    \end{tabular}
    \]

    We will use data smoothing techniques to create an approximating function that attempts to capture important patterns in the data.
    We assume that the following is true:
    \[ \lambda_1 f_1(x_i) + ... +  \lambda_n f_n(x_i) = y_i \ \ where \ \ i = 1,...,m \gg n \]
    From this, we can for construct the \(m * n \) linear system \(A\lambda = y \). \\
    We will use QR factorization to decompose and solve this system.\\

    This will be done using C++ and the \href{http://www.gnu.org/software/gsl/}{GNU Scientific Library}.
    In section~\ref{sec:solutions}, we will describe how we reached each solution, using the 
    most important parts from the code. Some basic knowledge of the GSL is assumed.

\bigskip
\bigskip
\section{Using the program}
    All of the C++ code for the program can be found in the main.cpp and in appendix A of this document.
    main.cpp comes accompanied by \mbox{data\_smoothing.sh}, which contains all of the necessary UNIX commands to generate the graph images.
    This file relies on the \href{https://www.gnu.org/software/plotutils/manual/en/html_node/graph.html}{graph} program
    in the GNU plotutils package to plot graphs, so make sure that it is installed.

    To compile and run the program, execute the following commands in the build/ directory:
\begin{lstlisting}
cmake ..
make
chmod +x ./data_smoothing.sh
./data_smoothing.sh
\end{lstlisting}
    Do not forget the .sh extension. All of the graphs will be present in the build/images/ directory. Output files which give some extra information 
    about the solutions can be found in build/output/ and in appendix B.
    
\newpage
\section{Solutions}
\label{sec:solutions}
    \subsection{Datapoints plot}
    We begin by plotting and examining the given datapoints.
    \begin{figure}[H]
        \centering
        \includegraphics[width=9cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/datapoints}
        \caption{The given data points}
    \end{figure}
    
    We notice that the plot of the points look like they follow a decreasing exponential function. We will plot the points \((x_i, \log(y_i)) \) next, 
    because we expect it might give us an easier relationship between x and y to work with.\\
    
    If we find that using the logarithmic function makes the relationship easier to work with, then we can create an approximating model \(g(x)\) for the points
    \((x_i, \log(y_i)) \). Afterwards, we can use \(\exp(g(x)) \) as an approximation for the originial data points.
    
    \subsection{Plot of \(\log(y_i)\)}
    \begin{figure}[H]
        \centering
        \includegraphics[width=9cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/log_datapoints}
        \caption{log of the given data points}
        \label{fig:logdata}
    \end{figure}
    As expected, we find a more pleasing relationship to work with. The graph of \((x_i, \log(y_i)) \) seems to be following a linear equation, which gives
    us a good idea of which base function \(f_k(x) \) where \(k = 1,...,n\) to use in 
    \[ \lambda_1 f_1(x_i) + ... +  \lambda_n f_n(x_i) = y_i \ \ \text{where} \ \ i = 1,...,m \gg n \]
    Since figure~\ref{fig:logdata} seems to follow a linear equation, we will use \mbox{\( f_k(x) = x^{k-1} \) where \(k = 1, 2 \)} to create an approximating 
    model. We then then get
    \[ \lambda_1 f_1(x_i) + \lambda_2 f_2(x_i) = y_i \]
    and can start constructing the overdetermined system of equations we will use to find the approximating model.
    
    \newpage
    \subsection{Setting up the system of equations}
    Now that we have a base function, we can fill in the system \( A\lambda = y \) we will work with. The system looks like this:
    \[
    \begin{bmatrix} f_1(x_i) & f_2(x_i) \end{bmatrix} 
    \times 
    \left[ \begin{array}{c}  \lambda_1 \\ \lambda_2  \end{array} \right]
    =
    \left[ \begin{array}{c} y_i \end{array} \right]
    \]
    
     \( A \) and \( y \) are constructed in the code as follows:
\begin{lstlisting}
gsl_matrix *A = gsl_matrix_alloc(size, n);
gsl_vector *Y = gsl_vector_alloc(size);

for (int i = 0; i < size; i++) {    //size = amount of points
    for (int j = 0; j < n; j++) {   //n = 2
        gsl_matrix_set(A, i, j, gsl_pow_int(xa1[i], j));
    }
    gsl_vector_set(Y, i, ya2[i]);
}
\end{lstlisting}
    Later, we will also construct the system with higher values for n (which we will call the degree) to see what happens to the approximation.

    \bigskip
    \subsection{QR factorization}
    Since the system \(A \lambda = y \) is overdetermined, we cannot solve it exactly, so we will find the least squares solution for it. 
    The least squares solution will minimize the Euclidean norm of the residual, \(||A\lambda - y||\). \\
    Before we do that, QR factorization will be used to decompose the matrix \( A \) into a product \( A = QR \) 
    of an orthogonal matrix \(Q\) and an upper triangular matrix \(R\). \\
    
    This is done very easily using GSL:
\begin{lstlisting}
gsl_linalg_QR_decomp(QR, tau);
gsl_linalg_QR_lssolve(QR, tau, Y, X, R);
\end{lstlisting}

    \newpage
    \subsection{Results}
    We get the following solution for the system:
\begin{lstlisting}
Vector X, solution found by solving after QR decomposition:
 2.10317965707954
-0.403985459719526
\end{lstlisting}
    These are the coefficients of the model \(g(x)\) for the points \((x_i, \log(y_i)) \). \\
    Thus, we have found that \[ g(x) = 2.10317965707954 - 0.403985459719526x\]
    The graph for g(x) along with the points \((x_i, \log(y_i)) \) can be seen on the left side in figure~\ref{fig:results}.
    \begin{figure}[H]
        \begin{minipage}[b]{0.49\textwidth}
            \includegraphics[width=6.5cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/gx_degree2}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.49\textwidth}
            \includegraphics[width=6.5cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/exp_gx_degree2}
        \end{minipage}
        \caption{The resulting models}
        \label{fig:results}
    \end{figure}
    
    Now that we have the model \(g(x)\), we can create an approximating model for the original data points.
    On the right side in figure~\ref{fig:results}, we plot \( exp(g(x)) \) to find that model. \\
    We now have what we were looking for: we can see the trend which the original data approximately follows. However, the experiment does not end here.
   
    \newpage
    \subsubsection{Condition number of \(A\)}
    We will calculate the condition number of matrix \(A\) to have some kind of measure for the accuracy of our solutions. Keep in mind, the condition number
    is not a direct representation of the accuracy of the solutions, but it plays a big role in it. A condition number with a high order of magnitude
    means that a small change in the input matrix \(A\) \emph{could} cause a significant change in the solutions, 
    whereas the opposite counts for condition numbers with smaller orders of magnitude.\\
    To calculate the condition number of A, we will use the following definition: \[\kappa(A)= \frac{|max(S)|}{|min(S)|} \]
    where S is the vector of singular values of A. In GSL, we can find S by using gsl\_linalg\_SV\_decomp.
\begin{lstlisting}
gsl_linalg_SV_decomp(U, V, S, work);
double condNumber, minS, maxS;
minS = gsl_vector_get(S, 0);
maxS = gsl_vector_get(S, 0);
for (int j = 0; j < n; j++) {
    if (gsl_vector_get(S, j) < minS) minS = gsl_vector_get(S, j);
    if (gsl_vector_get(S, j) > maxS) maxS = gsl_vector_get(S, j);
}
condNumber = fabs(maxS) / fabs(minS);
\end{lstlisting}
    After doing this, we find a condition number of about 8 (see appendix~\ref{sec:degree2}). 
    Thus, we can conclude that our solution \[ \exp(g(x)) = \exp(2.10317965707954 - 0.403985459719526x) \]
    is a pretty accurate approximation model for the given datapoints if we choose n to be 2. 
    However, if we look at the solution when we use higher degrees n, things become very different.
    
    \subsection{Higher degrees n}
    \label{sec:higherdegrees}
    In figures~\ref{fig:n4} and~\ref{fig:n7} the graphs for the models where \(n=4\) and \(n=7\) can be seen. The coefficients used to calculate points for 
    the graphs can be seen in vector X in the output files in appendix~\ref{sec:output}. We notice that the graphs seem to display
    the trend which the data follows better than the case where \(n=2\). More specifically, they have minimized the sum of the squares
    of the residuals better. We can confirm this by looking at the residual vector \(r = y - A\lambda\) in the output files,
    they decrease as n increases.
    However, this comes at the cost of more processing power, since the matrix \(A\) increases in size as n increases.
    \newpage
    \begin{figure}[H]
        \begin{minipage}[b]{0.49\textwidth}
            \includegraphics[width=6.5cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/gx_degree4}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.49\textwidth}
            \includegraphics[width=6.5cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/exp_gx_degree4}
        \end{minipage}
        \caption{Graphs for n = 4}
        \label{fig:n4}
    \end{figure}
    
    \begin{figure}[H]
        \begin{minipage}[b]{0.49\textwidth}
            \includegraphics[width=6.5cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/gx_degree7}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.49\textwidth}
            \includegraphics[width=6.5cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/exp_gx_degree7}
        \end{minipage}
        \caption{Graphs for n = 7}
        \label{fig:n7}
    \end{figure}
    In the output files, we can also see that the condition number becomes very large as n increases, up to around 6\mbox{\sc{e}}6 for \(n = 7\). 
    This means that a small change in the input matrix \(A\) could cause significant changes in the results. This makes sense, because matrix \(A\) 
    contains elements like \(x^n\), and these could multiply potential errors in the matrix by a big margin.
    
    \subsection{Improving the solutions}
    In order to get more reliable results, we will rescale the given datapoints to fit in the interval \([-1, 1]\). This will make the
    values \(x^n\) in the matrix \(A\) much safer to use. To rescale the the points, we use the following formula:
    \[x' = (b-a)\frac{x - \min(x_i)}{\max(x_i) - \min(x_i)} + a = (1+1)\frac{x - 0.635}{5.435 - 0.635} - 1 = \frac{2x - 1.27}{4.8} - 1 \]
    In figures~\ref{fig:n2_r} and~\ref{fig:n7_r}, we see the the graphs after rescaling the points; they look exactly the same as before rescaling. 
    If we examine the output of the program (appendices \ref{sec:degree2_r} and further), we find that the condition number has indeed decreased.
    It decreased from 7.9 to 1.5 for \(n = 2\), from 842.5 to 6.8 for \(n = 4\), and from around 6\mbox{\sc{e}}6 to 189.8 for \(n=7\).
    The condition numbers after rescaling are much more favorable to work with.
    Another thing to note, is that the residual vectors also decreased after rescaling the data points.
    
    Thus, we can conclude that rescaling the data points to fit in the interval \([-1, 1]\) has indeed improved our results.
    Another way to improve the results would be to use Legendre Polynomials as base functions instead of \( f_k(x) = x^k \), but they are not used
    in these solutions.
    \begin{figure}[H]
        \begin{minipage}[b]{0.49\textwidth}
            \includegraphics[width=6.5cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/gx_degree2_rescaled}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.49\textwidth}
            \includegraphics[width=6.5cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/exp_gx_degree2_rescaled}
        \end{minipage}
        \caption{Graphs for n = 2}
        \label{fig:n2_r}
    \end{figure}
    
    \begin{figure}[H]
        \begin{minipage}[b]{0.49\textwidth}
            \includegraphics[width=6.5cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/gx_degree7_rescaled}
        \end{minipage}
        \hfill
        \begin{minipage}[b]{0.49\textwidth}
            \includegraphics[width=6.5cm, trim={2cm, 4cm, 2cm, 3cm}, clip]{../build/images/exp_gx_degree7_rescaled}
        \end{minipage}
        \caption{Graphs for n = 7}
        \label{fig:n7_r}
    \end{figure}

\onecolumn
\appendix
\appendixpage
\addappheadtotoc

\section{Code}
	\subsection{main.cpp}
		\lstinputlisting[basicstyle=\scriptsize]{../main.cpp}
	\bigskip
	\subsection{data\_smoothing.sh}
		\lstinputlisting[basicstyle=\scriptsize]{../build/data_smoothing.sh}

\newpage
\section{Output}
\label{sec:output}
	\subsection{output\_degree2.txt}
	\label{sec:degree2}
		\lstinputlisting[basicstyle=\scriptsize]{../build/output/output_degree2.txt} 
	\subsection{output\_degree4.txt}
		\lstinputlisting[basicstyle=\scriptsize]{../build/output/output_degree4.txt} 
	\subsection{output\_degree7.txt}
		\lstinputlisting[basicstyle=\scriptsize]{../build/output/output_degree7.txt} 
	\subsection{output\_degree2\_rescaled.txt}
	\label{sec:degree2_r}
		\lstinputlisting[basicstyle=\scriptsize]{../build/output/output_degree2_rescaled.txt} 
	\subsection{output\_degree4\_rescaled.txt}
		\lstinputlisting[basicstyle=\scriptsize]{../build/output/output_degree4_rescaled.txt} 
	\subsection{output\_degree7\_rescaled.txt}
	\label{sec:degree7_r}
		\lstinputlisting[basicstyle=\scriptsize]{../build/output/output_degree7_rescaled.txt} 
		
\end{document}